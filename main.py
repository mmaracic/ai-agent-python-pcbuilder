import logging
import os
from typing import Annotated, Optional

from fastapi import FastAPI, Request
from fastapi.params import Body, Depends
from langchain.chat_models.base import BaseChatModel
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage
from langchain_core.runnables import RunnableConfig
from pydantic import SecretStr
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import START, MessagesState, StateGraph
from langgraph.graph.state import CompiledStateGraph

# Constants
OPEN_ROUTER_API_KEY = "OPEN_ROUTER_API_KEY"
OPEN_ROUTER_API_KEY_ERROR = "OPEN_ROUTER_API_KEY environment variable is not set"
MODEL_NOT_INITIALIZED_ERROR = "Model is not initialized. Please call /setup first."

class AppState:
    """
    Holds application-wide state, such as the chat model instance.
    """
    def __init__(self):
        self.model: Optional[BaseChatModel] = None
        self.compiled_graph: Optional[CompiledStateGraph] = None

app = FastAPI()
app.state.app_state = AppState()
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def get_state(request: Request) -> AppState:
    """
    Retrieves the application state from the request.

    Returns:
        AppState: The current application state.
    """
    return request.app.state.app_state

@app.get("/setup")
def setup(application_state: Annotated[AppState, Depends(get_state)]) -> None:
    """
    Initializes the FastAPI application by checking for the required
    environment variable and setting up the chat model.
    Raises:
        ValueError: If the OPENAI_API_KEY environment variable is not set.
    """
    logger.info("Initializing FastAPI application")
    if not os.environ.get(OPEN_ROUTER_API_KEY):
        logger.error(OPEN_ROUTER_API_KEY_ERROR)
        raise ValueError(OPEN_ROUTER_API_KEY_ERROR)

    application_state.model = ChatOpenAI(
        model="mistralai/mistral-small-3.2-24b-instruct:free",
        api_key=SecretStr(os.environ[OPEN_ROUTER_API_KEY]),
        base_url="https://openrouter.ai/api/v1",
        default_headers={"HTTP-Referer": "https://mysite", "X-Title": "My App"},
    )

    def call_model(state: MessagesState):
        if not application_state.model:
            logger.error(MODEL_NOT_INITIALIZED_ERROR)
            raise ValueError(MODEL_NOT_INITIALIZED_ERROR)

        response = application_state.model.invoke(state["messages"])
        return {"messages": response}
    
    graph = StateGraph(
        state_schema=MessagesState
    )
    graph.add_edge(START, "model")
    graph.add_node(node="model", action=call_model)
    application_state.compiled_graph = graph.compile(checkpointer=MemorySaver())

    logger.info("FastAPI application initialized successfully")

@app.post("/query")
def query(state: Annotated[AppState, Depends(get_state)], text: Annotated[str, Body(media_type="text/plain")], user_id: str = "default_user"):
    """
    Handles POST requests to the '/query' endpoint.

    Args:
        request (Request): The incoming HTTP request object.
        text (str): The text provided in the request body.

    Returns:
        dict: A dictionary containing the response from the model.

    Logs:
        - The received query.
        - The response generated by the model.
    """
    if not state.compiled_graph:
        logger.error(MODEL_NOT_INITIALIZED_ERROR)
        return {"response": MODEL_NOT_INITIALIZED_ERROR}
    logger.info("Received query: %s from user %s", text, user_id)

    config = RunnableConfig(configurable= {"thread_id": user_id})
    input_messages = [HumanMessage(text)]
    response = state.compiled_graph.invoke({"messages": input_messages}, config)
    
    logger.info("Message count in history: %d", len(response["messages"]))
    return {"response": response["messages"][-1].pretty_print()}
    